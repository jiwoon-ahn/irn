from torch.utils.data import Dataset, DataLoader

from enum import Enum, auto

from cityscapes.dataloader import *
from step.divide_to_patches import divide_to_patches
import glob
import typing
import torch
from torch import nn
from torchvision.transforms import Resize, InterpolationMode
import cv2
import pytorch_lightning as pl
from cityscapes.divided_dataset import CityScapesDividedDataset, Divide

class CityScapesDividedModule(pl.LightningDataModule):
    def __init__(self, batch_size: int, patch_size: int, datatype: list[str], transform: typing.Optional[typing.Callable]) -> None:
        super().__init__()
        self.batch_size = batch_size
        self.patch_size = patch_size
        self.datatype = datatype
        self.transform = transform
        self.columns_per_image = self._full_width // patch_size
        self.rows_per_image = self._full_height // patch_size
        self.patches_per_image = self.rows_per_image * self.columns_per_image
        self.train_dataset = CityScapesDividedDataset(Divide.Train, datatype, patch_size, transform)
        self.val_dataset = CityScapesDividedDataset(Divide.Val, datatype, patch_size, transform)
        self.test_dataset = CityScapesDividedDataset(Divide.Test, datatype, patch_size, transform)

    def prepare_data(self) -> None:
        return super().prepare_data()

    def train_dataloader(self):
        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)

    def val_dataloader(self):
        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4)

    def test_dataloader(self):
        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4)

    def __getitem__(self, index):
        return self.dataset[index]

    def __len__(self):
        return len(self.dataset)